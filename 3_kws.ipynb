{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7865b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import librosa\n",
    "\n",
    "from kws_dataloader import KWSLazyDataset, load_opus_ffmpeg, logmel, SEG_SEC, SR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d4426c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = Path(\"train_opus\")\n",
    "TEST_DIR  = Path(\"test_opus\")\n",
    "\n",
    "TRAIN_AUDIO = TRAIN_DIR / \"audio\"\n",
    "TEST_AUDIO  = TEST_DIR  / \"audio\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed55971f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_files: 90000 bounds: 45000\n"
     ]
    }
   ],
   "source": [
    "with open(TRAIN_DIR / \"word_bounds.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    bounds = json.load(f)\n",
    "\n",
    "train_files = sorted(TRAIN_AUDIO.glob(\"*.opus\"))\n",
    "print(\"train_files:\", len(train_files), \"bounds:\", len(bounds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fefb18a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90000/90000 [00:00<00:00, 663114.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos: 45000 neg: 45000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pos_ids = set(bounds.keys())\n",
    "\n",
    "pos = []\n",
    "neg = []\n",
    "\n",
    "for p in tqdm(train_files):\n",
    "    audio_id = p.stem\n",
    "    if audio_id in pos_ids:\n",
    "        s, e = bounds[audio_id]\n",
    "        pos.append((str(p), 1, float(s), float(e)))\n",
    "    else:\n",
    "        neg.append((str(p), 0, None, None))\n",
    "\n",
    "print(\"pos:\", len(pos), \"neg:\", len(neg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0904d0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: 90000\n"
     ]
    }
   ],
   "source": [
    "NEG_RATIO = 1   # 1 позитив : 1 негатив\n",
    "random.seed(42)\n",
    "\n",
    "neg_sample = random.sample(neg, k=min(len(neg), len(pos) * NEG_RATIO))\n",
    "examples = pos + neg_sample\n",
    "random.shuffle(examples)\n",
    "\n",
    "print(\"examples:\", len(examples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24f279b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_files: 90000\n",
      "pos from json: 45000\n",
      "neg total: 45000\n",
      "examples: 90000\n",
      "examples pos/neg: 45000 45000\n"
     ]
    }
   ],
   "source": [
    "print(\"train_files:\", len(train_files))\n",
    "print(\"pos from json:\", len(pos))\n",
    "print(\"neg total:\", len(neg))\n",
    "print(\"examples:\", len(examples))\n",
    "print(\"examples pos/neg:\", sum(1 for _,lab,_,_ in examples if lab==1),\n",
    "      sum(1 for _,lab,_,_ in examples if lab==0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2be7dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 72000 val: 18000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = np.array([lab for _, lab, _, _ in examples], dtype=np.int64)\n",
    "idx = np.arange(len(examples))\n",
    "\n",
    "tr_idx, va_idx = train_test_split(idx, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "train_ex = [examples[i] for i in tr_idx]\n",
    "val_ex   = [examples[i] for i in va_idx]\n",
    "\n",
    "print(\"train:\", len(train_ex), \"val:\", len(val_ex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "979c94dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_TRAIN = 64\n",
    "BATCH_VAL = 128\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "train_dl = DataLoader(KWSLazyDataset(train_ex), batch_size=BATCH_TRAIN, shuffle=True,\n",
    "                      num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_dl   = DataLoader(KWSLazyDataset(val_ex), batch_size=BATCH_VAL, shuffle=False,\n",
    "                      num_workers=NUM_WORKERS, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9866f0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feat = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "        self.head = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.feat(x).flatten(1)\n",
    "        return self.head(z).squeeze(1)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CNN().to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "crit = nn.BCEWithLogitsLoss()\n",
    "\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "955f497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(\"device:\", device)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7820622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_metric(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    pos = y_true == 1\n",
    "    neg = y_true == 0\n",
    "    NUM_POS = pos.sum()\n",
    "    NUM_NEG = neg.sum()\n",
    "\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "\n",
    "    FRR = FN / max(1, NUM_POS)\n",
    "    FAR = FP / max(1, NUM_NEG)\n",
    "\n",
    "    a = 1.0 - FRR\n",
    "    b = 1.0 - FAR\n",
    "    return 2*a*b / max(1e-12, (a + b))\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_probs(dl):\n",
    "    model.eval()\n",
    "    probs, ys = [], []\n",
    "    for x, yb in dl:\n",
    "        x = x.to(device)\n",
    "        p = torch.sigmoid(model(x)).cpu().numpy()\n",
    "        probs.append(p)\n",
    "        ys.append(yb.numpy())\n",
    "    return np.concatenate(probs), np.concatenate(ys)\n",
    "\n",
    "def find_best_threshold(y_true, probs):\n",
    "    ts = np.linspace(0.05, 0.95, 91)\n",
    "    best_s, best_t = -1.0, 0.5\n",
    "    for t in ts:\n",
    "        pred = (probs >= t).astype(int)\n",
    "        s = score_metric(y_true, pred)\n",
    "        if s > best_s:\n",
    "            best_s, best_t = s, t\n",
    "    return best_s, best_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9bd99eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 1125/1125 [14:43<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train_loss=0.6255 val_score=0.7375 best_thr=0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|██████████| 1125/1125 [14:45<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: train_loss=0.5183 val_score=0.7861 best_thr=0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|██████████| 1125/1125 [14:52<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: train_loss=0.4603 val_score=0.8082 best_thr=0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4: 100%|██████████| 1125/1125 [14:45<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: train_loss=0.4368 val_score=0.8184 best_thr=0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5: 100%|██████████| 1125/1125 [14:43<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: train_loss=0.4146 val_score=0.8255 best_thr=0.54\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for x, yb in tqdm(train_dl, desc=f\"epoch {epoch}\"):\n",
    "        x = x.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = crit(logits, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running += float(loss.item()) * x.size(0)\n",
    "        n += x.size(0)\n",
    "\n",
    "    val_probs, val_y = eval_probs(val_dl)\n",
    "    best_s, best_t = find_best_threshold(val_y, val_probs)\n",
    "    print(f\"epoch {epoch}: train_loss={running/n:.4f} val_score={best_s:.4f} best_thr={best_t:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f1dd272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(y: np.ndarray, sr: int, seg_sec=SEG_SEC, hop_sec=0.3):\n",
    "    seg = int(seg_sec * sr)\n",
    "    hop = int(hop_sec * sr)\n",
    "    if len(y) <= seg:\n",
    "        yield np.pad(y, (0, seg - len(y)))\n",
    "        return\n",
    "    for start in range(0, len(y) - seg + 1, hop):\n",
    "        yield y[start:start+seg]\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_record(path: str, thr: float, hop_sec=0.3):\n",
    "    y = load_opus_ffmpeg(path, sr=SR)\n",
    "    feats = []\n",
    "    for seg in sliding_windows(y, SR, seg_sec=SEG_SEC, hop_sec=hop_sec):\n",
    "        feats.append(logmel(seg, sr=SR))\n",
    "    Xw = torch.from_numpy(np.stack(feats)).unsqueeze(1).to(device)  # [K,1,80,T]\n",
    "    probs = torch.sigmoid(model(Xw)).cpu().numpy()\n",
    "    p = float(probs.max())\n",
    "    return int(p >= thr), p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07fb69d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_files: 27000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/r.gulyamov/VkEducation/speech_technology_mipt/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_val_score: 0.8267114033910438 thr: 0.49999999999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27000/27000 [25:48<00:00, 17.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000219778122723066859323624505982384475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000920560142346477464477964040846645823</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002106775361063830068199242310438122126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002161736146841817059430282255903999813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002303832386140303186933286284938192307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  label\n",
       "0  0000219778122723066859323624505982384475      1\n",
       "1  0000920560142346477464477964040846645823      1\n",
       "2  0002106775361063830068199242310438122126      1\n",
       "3  0002161736146841817059430282255903999813      0\n",
       "4  0002303832386140303186933286284938192307      1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files = sorted(TEST_AUDIO.glob(\"*.opus\"))\n",
    "print(\"test_files:\", len(test_files))\n",
    "\n",
    "val_probs, val_y = eval_probs(val_dl)\n",
    "best_s, best_thr = find_best_threshold(val_y, val_probs)\n",
    "print(\"best_val_score:\", best_s, \"thr:\", best_thr)\n",
    "\n",
    "rows = []\n",
    "for p in tqdm(test_files):\n",
    "    label, prob = predict_record(str(p), thr=best_thr, hop_sec=0.3)\n",
    "    rows.append((p.stem, label))\n",
    "\n",
    "sub = pd.DataFrame(rows, columns=[\"id\", \"label\"])\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "sub.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
